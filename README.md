# PromptEval: Testing and Documenting the Effectiveness of AI Prompts using Python + Power BI

## ğŸ” Overview
PromptEval is a lightweight evaluation framework for testing and documenting the effectiveness of prompts across AI tools like ChatGPT and GitHub Copilot. It automates prompt execution using Python and visualizes results in Power BI, allowing users to iterate, score, and refine prompt strategies for tasks like summarization, explanation, and code generation.

---

## ğŸ“ Project Structure
PromptEval/
â”œâ”€â”€ prompts/ # JSON prompt templates
â”œâ”€â”€ results/ # Output and scoring CSVs
â”œâ”€â”€ scripts/ # Python execution scripts
â”œâ”€â”€ powerbi/ # Power BI dashboard file
â”œâ”€â”€ docs/ # Markdown documentation
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

---

## âš™ï¸ Technologies Used
- **Python** for running prompt tests and storing results
- **OpenAI API** for ChatGPT integration
- **Power BI** for data visualization
- **Git** for version control and collaboration
- **Markdown** for documenting best practices and prompt iterations

---
